{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f36e83",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-15T04:03:15.679016Z",
     "iopub.status.busy": "2024-09-15T04:03:15.677666Z",
     "iopub.status.idle": "2024-09-15T04:03:16.142095Z",
     "shell.execute_reply": "2024-09-15T04:03:16.140888Z"
    },
    "papermill": {
     "duration": 0.473125,
     "end_time": "2024-09-15T04:03:16.145158",
     "exception": false,
     "start_time": "2024-09-15T04:03:15.672033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60e874",
   "metadata": {
    "papermill": {
     "duration": 0.002307,
     "end_time": "2024-09-15T04:03:16.150230",
     "exception": false,
     "start_time": "2024-09-15T04:03:16.147923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch Essentials for Deep Learning\n",
    "\n",
    "Deep learning has revolutionized fields ranging from computer vision to natural language processing. PyTorch, an open-source deep learning framework developed by Facebook's AI Research lab, has become a popular choice among researchers and practitioners due to its flexibility, ease of use, and dynamic computation graph. This article covers the essentials of PyTorch, providing a foundation for building and training deep learning models.\n",
    "\n",
    "# 1. Introduction to PyTorch\n",
    "PyTorch is a deep learning framework that provides a wide range of functionalities for building and training neural networks. Its core features include:\n",
    "\n",
    "Dynamic Computation Graphs: PyTorch uses dynamic computation graphs, which allows for more flexibility and ease of debugging compared to static graphs used by other frameworks like TensorFlow.\n",
    "Autograd: PyTorch's automatic differentiation library automatically computes gradients, which is essential for backpropagation and optimization.\n",
    "TorchScript: For production deployment, PyTorch offers TorchScript, a way to serialize and optimize models.\n",
    "# 2. Basic Concepts\n",
    "Tensors\n",
    "At the heart of PyTorch is the Tensor object, which is similar to NumPy arrays but with additional support for GPU acceleration. Tensors are multidimensional arrays with support for various mathematical operations.\n",
    "\n",
    "## Creating Tensors:\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Creating a tensor from a list\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Creating a tensor filled with zeros\n",
    "zeros = torch.zeros(3)\n",
    "\n",
    "# Creating a tensor filled with ones\n",
    "ones = torch.ones(3)\n",
    "\n",
    "# Creating a tensor with random values\n",
    "random_tensor = torch.rand(3)\n",
    "```\n",
    "\n",
    "## Autograd\n",
    "PyTorchâ€™s autograd module provides automatic differentiation for all operations on Tensors. This is crucial for training neural networks using gradient descent.\n",
    "\n",
    "Basic Autograd Usage:\n",
    "\n",
    "```python\n",
    "# Create a tensor with requires_grad=True to track computations\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations\n",
    "y = x + 2\n",
    "z = y.mean()\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(x.grad)\n",
    "```\n",
    "\n",
    "# 3. Building Neural Networks\n",
    "PyTorch provides the torch.nn module to build neural networks. The nn.Module class is the base class for all neural network modules, and it helps in defining layers and the forward pass.\n",
    "\n",
    "Defining a Simple Neural Network:\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "\n",
    "## Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "```\n",
    "# 4. Training and Evaluation\n",
    "Training a model involves several steps: forward pass, loss computation, backward pass, and optimization.\n",
    "\n",
    "Training Loop Example:\n",
    "\n",
    "```python\n",
    "## Dummy data\n",
    "inputs = torch.randn(32, 10)\n",
    "labels = torch.randint(0, 2, (32,))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item()}')\n",
    "Evaluation: Evaluation typically involves switching the model to evaluation mode using model.eval(), and performing inference without computing gradients.\n",
    "```\n",
    "\n",
    "## Evaluation Example:\n",
    "\n",
    "```python\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.randn(10, 10)\n",
    "    predictions = model(test_inputs)\n",
    "    print(predictions)\n",
    "```\n",
    "# 5. GPU Acceleration\n",
    "PyTorch supports GPU acceleration using CUDA. You can move tensors and models to the GPU by calling .to('cuda').\n",
    "\n",
    "Using GPU:\n",
    "\n",
    "```python\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Move tensors to GPU\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass and loss computation\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "```\n",
    "\n",
    "# 6. Saving and Loading Models\n",
    "PyTorch provides methods to save and load models, which is essential for model persistence and deployment.\n",
    "\n",
    "Saving and Loading Example:\n",
    "\n",
    "```python\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Load the model\n",
    "model = SimpleNN()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "```\n",
    "\n",
    "# Conclusion\n",
    "PyTorch is a powerful and flexible framework that has become a favorite for deep learning research and production. With its dynamic computation graph, automatic differentiation, and ease of use, it simplifies the development of complex models and provides robust support for GPU acceleration. Mastering PyTorch essentials will equip you with the tools needed to tackle a wide range of deep learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42e3ad",
   "metadata": {
    "papermill": {
     "duration": 0.002086,
     "end_time": "2024-09-15T04:03:16.154742",
     "exception": false,
     "start_time": "2024-09-15T04:03:16.152656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.035132,
   "end_time": "2024-09-15T04:03:16.679305",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-15T04:03:12.644173",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
